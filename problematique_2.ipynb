{
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "name": "",
  "signature": "sha256:46290fae39b364ce15f46852eb5722c4a698c6bd84718e9c1ec8e836cb760474"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Pr\u00e9dire la victoire d'une \u00e9quipe"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Ismael Bonneau et Issam Benamara\n",
      "\n",
      "donn\u00e9es: https://www.kaggle.com/hugomathien/soccer\n",
      "\n",
      "inspiration et remerciements : http://ml-cheatsheet.readthedocs.io/en/latest/nn_concepts.html"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Ismael Bonneau et Issam Benamara"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Description du probl\u00e8me"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Pr\u00e9dire les victoires\n",
      "\n",
      "blablabla\n",
      "blablabla\n",
      "blablabla\n",
      "blablabla\n",
      "blablabla\n",
      "blablabla"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Mod\u00e8le"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "comparaison de diff\u00e9rents mod\u00e8les\n",
      "\n",
      "blaaablablabla"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Code"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import matplotlib.pyplot as plt\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import sqlite3\n",
      "from sklearn.model_selection import train_test_split\n",
      "%matplotlib inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "tables : Player_Attributes, Player, Team, Team_Attributes, Match, League, Country\n",
      "\"\"\"\n",
      "from datetime import datetime\n",
      "\n",
      "path = \"./data/\"  #chemin vers la base de donn\u00e9es\n",
      "\n",
      "database = path + 'soccer.sqlite'\n",
      "\n",
      "\n",
      "conn = sqlite3.connect(database)\n",
      "\n",
      "attributes = [\"home_team_goal\", \"away_team_goal\"]\n",
      "homeAtt = [\"buildUpPlayDribbling\", \"buildUpPlayPassing\", \"defencePressure\", \"defenceTeamWidth\", \n",
      "              \"defenceAggression\", \"buildUpPlaySpeed\", \"chanceCreationCrossing\", \"chanceCreationShooting\",\n",
      "              \"chanceCreationPassing\", \"buildUpPlayPassing\"]\n",
      "homeAtt = [\"t1.\" + s + \" AS \"+ s + \"Home\" for s in homeAtt]\n",
      "awayAtt = [\"buildUpPlayDribbling\", \"buildUpPlayPassing\", \"defencePressure\", \"defenceTeamWidth\", \n",
      "              \"defenceAggression\", \"buildUpPlaySpeed\", \"chanceCreationCrossing\", \"chanceCreationShooting\",\n",
      "              \"chanceCreationPassing\", \"buildUpPlayPassing\"]\n",
      "awayAtt = [\"t2.\" + s + \" AS \"+ s + \"Away\" for s in awayAtt]\n",
      "\n",
      "att = homeAtt + awayAtt + attributes\n",
      "\n",
      "query = \"SELECT \"\n",
      "query += \", \".join(att)\n",
      "query += \" FROM Team_Attributes t1, Team_Attributes t2, Match\"\n",
      "query += \" WHERE t1.team_api_id=home_team_api_id AND t2.team_api_id=away_team_api_id\"\n",
      "\n",
      "matches = pd.read_sql(query, conn)\n",
      "\n",
      "conn.close()\n",
      "\n",
      "print(\"notre table contient \" + str(matches.shape[0]) + \" enregistrements d'equipes\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "notre table contient 781625 enregistrements d'equipes\n"
       ]
      }
     ],
     "prompt_number": 57
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#calculer les victoires\n",
      "\n",
      "matches = matches.fillna(value=50)\n",
      "\n",
      "resultats = []\n",
      "for index, row in matches.iterrows():\n",
      "    if row[\"home_team_goal\"] > row[\"away_team_goal\"]:\n",
      "        resultats.append(0)\n",
      "    if row[\"home_team_goal\"] < row[\"away_team_goal\"]:\n",
      "        resultats.append(1)\n",
      "    if row[\"home_team_goal\"] == row[\"away_team_goal\"]:   \n",
      "        resultats.append(0)\n",
      "    #on rajoute une colonne \"victory qui vaut 0 en cas de HOME, 1 pour AWAY ou 0 en cas de nul\"\n",
      "    matches[\"victory\"] = pd.Series(resultats)\n",
      "\n",
      "    \n",
      "Y = matches[\"victory\"]\n",
      "Y = Y.as_matrix()\n",
      "Y.reshape((1, len(Y)))\n",
      "\n",
      "matches = matches.drop([\"away_team_goal\", \"home_team_goal\", \"victory\"], axis=1)\n",
      "X = matches.as_matrix().T\n",
      "print(X.shape)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.05, random_state=42)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class simplePerceptron:\n",
      "    \"\"\"\n",
      "    classe impl\u00e9mentant le perceptron classique,\n",
      "    avec simoid comme fonction d'activation et descente de gradient.\n",
      "    \"\"\"\n",
      "    \n",
      "    def __init__(self, inputdim):\n",
      "        self.inputdim = inputdim\n",
      "    \n",
      "    \n",
      "    def sigmoid(self, x):\n",
      "        \"\"\"\n",
      "        Calcule sigmoid(x)\n",
      "        \"\"\"\n",
      "        return 1.0 / (1+np.exp(-x))\n",
      "    \n",
      "    def initialiser(dim):\n",
      "        \"\"\"\n",
      "        initialise le vecteur w al\u00e9atoirement et le biais b\n",
      "        \"\"\"\n",
      "        w = np.random.randn(dim, 1) * 0.01\n",
      "        b = 0\n",
      "\n",
      "        return w, b\n",
      "\n",
      "    def propagate(w, b, X, Y):\n",
      "        \"\"\"\n",
      "        forward propagation de la matrice X\n",
      "        X contient m exemples qui sont propag\u00e9s en une seule fois.\n",
      "        retourne le cost (moyenne des m erreurs)\n",
      "\n",
      "        utilise la fonction \"Cross-entropy loss\"\n",
      "        \"\"\"\n",
      "    \n",
      "        m = X.shape[1]\n",
      "        A = sigmoid(np.dot(self.w.T, X) + b)\n",
      "\n",
      "        cost = -1.0/m*np.sum(Y*np.log(A) + (1-Y)*np.log(1-A))\n",
      "\n",
      "        dw = 1/m*np.dot(X, (A - Y).T)\n",
      "        db = 1/m*np.sum((A - Y))\n",
      "\n",
      "        cost = np.squeeze(cost)\n",
      "\n",
      "        gradients = {\"dw\": dw,\n",
      "                 \"db\": db}\n",
      "\n",
      "        return gradients, cost\n",
      "    \n",
      "\n",
      "    def optimise(w, b, X, Y, nbiterations=2000, learning_rate=0.01, verbose=False):\n",
      "        \"\"\"\n",
      "        optimisation de w et b pour m exemples en m\u00eame temps.\n",
      "        \"\"\"\n",
      "\n",
      "        costs = []\n",
      "\n",
      "        for i in range(nubiterations):\n",
      "            #forward propagation\n",
      "            gradients, cost = propagate(w, b, X, Y)\n",
      "\n",
      "            #on r\u00e9cup\u00e8re les gradients\n",
      "            dw = gradients[\"dw\"]\n",
      "            db = gradients[\"db\"]\n",
      "            #on met \u00e0 jour w et b\n",
      "            w = w - learning_rate * dw\n",
      "            b = b - learning_rate * db\n",
      "\n",
      "            if i % 100 == 0:\n",
      "                costs.append(cost)\n",
      "\n",
      "        params = {\"w\": w,\n",
      "                  \"b\": b}\n",
      "\n",
      "        return params, costs\n",
      "\n",
      "    \n",
      "    \n",
      "    def predict(self, w, b, X):\n",
      "        \"\"\"\n",
      "        prediction sur un ensemble de m exemples\n",
      "        renvoie 0 ou 1\n",
      "        \"\"\"\n",
      "\n",
      "        m = X.shape[1]\n",
      "        Y_prediction = np.zeros((1,m))\n",
      "        w = w.reshape(X.shape[0], 1)\n",
      "\n",
      "        A = sigmoid(np.dot(self.w.T, X) + b)\n",
      "\n",
      "        for i in range(A.shape[1]):\n",
      "            Y_prediction = np.where(A>0.5, 1, 0)\n",
      "\n",
      "        return Y_prediction\n",
      "\n",
      "\n",
      "    def run(self, X_train, Y_train, X_test, Y_test, nbiterations=2000, learning_rate=0.01):\n",
      "        \"\"\"\n",
      "        \"\"\"\n",
      "    \n",
      "        self.w, self.b = initialiser(X_train.shape[0])\n",
      "    \n",
      "        parameters, costs = optimize(w, b, X_train, Y_train, nbiterations, learning_rate, verbose=False)\n",
      "    \n",
      "        self.w = parameters[\"w\"]\n",
      "        self.b = parameters[\"b\"]\n",
      "    \n",
      "        # calculer l'accuracy test / train\n",
      "        Y_prediction_test = predict(w, b, X_test)\n",
      "        Y_prediction_train = predict(w, b, X_train)\n",
      "    \n",
      "        print(\"train accuracy: {} %\".format(100 - np.mean(np.abs(Y_prediction_train - Y_train)) * 100))\n",
      "        print(\"test accuracy: {} %\".format(100 - np.mean(np.abs(Y_prediction_test - Y_test)) * 100))\n",
      "    \n",
      "        return self.w, self.b, costs, Y_prediction_test, Y_prediction_train"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class hiddenLayerPerceptron:\n",
      "    \"\"\"\n",
      "    impl\u00e9mente un r\u00e9seau de neurones \u00e0 un seul hidden layer.\n",
      "    mod\u00e8le : tanh -> sigmoid\n",
      "    \"\"\"\n",
      "    \n",
      "    def initialize_parameters(n_x, n_h, n_y):\n",
      "    \"\"\"\n",
      "    \n",
      "    \"\"\"\n",
      "    # w et b du input layer :\n",
      "    w1 = np.random.randn(n_h, n_x) * 0.01\n",
      "    b1 = np.zeros((n_h, 1))\n",
      "    \n",
      "    # w et b hiden layer :\n",
      "    w2 = np.random.randn(n_y, n_h) * 0.01\n",
      "    b2 = np.zeros((n_y, 1))\n",
      "       \n",
      "    parameters = {\"w1\": w1,\n",
      "                  \"b1\": b1,\n",
      "                  \"w2\": w2,\n",
      "                  \"b2\": b2}\n",
      "    \n",
      "    return parameters"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}